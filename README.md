ğŸ® Reinforcement Learning in Celeste Classic

Ten projekt wykorzystuje Deep Q-Network (DQN) do nauki agenta przechodzenia gry Celeste Classic, wymagajÄ…cej platformÃ³wki opartej na precyzyjnych ruchach. Agent RL uczy siÄ™ poruszaÄ‡, skakaÄ‡ i unikaÄ‡ przeszkÃ³d, analizujÄ…c zrzuty ekranu z gry bez dostÄ™pu do wewnÄ™trznego stanu gry. Celem byÅ‚o sprawdzenie, czy agent moÅ¼e opanowaÄ‡ podstawowe mechaniki tylko na podstawie danych wizyjnych.

Projekt Å‚Ä…czy:

â€¢ gÅ‚Ä™bokie uczenie (CNN),

â€¢ sterowanie klawiaturÄ… przez pyautogui,

â€¢ przetwarzanie obrazu i system nagrÃ³d,

â€¢ oraz uczenie poprzez eksploracjÄ™ Å›rodowiska gry.


âš™ï¸ DziaÅ‚anie programu

1. Inicjalizacja Å›rodowiska i agenta:
  
  â€¢ Monitorowanie okreÅ›lonego obszaru ekranu z grÄ….
  
  â€¢ Definicja 17 moÅ¼liwych akcji (ruchy, skoki, dash).
  
  â€¢ Budowa sieci neuronowej (CNN + Dense) oraz target network.
  
  â€¢ Ustawienie epsilon = 1.0 (peÅ‚na eksploracja na starcie).

2. Trening agenta:
  
  â€¢ Reset gry i wykrywanie pozycji gracza (analiza kolorÃ³w).
  
  â€¢ Co krok: wybÃ³r akcji, jej wykonanie, obserwacja rezultatu, zapis doÅ›wiadczenia.
  
  â€¢ System nagrÃ³d bazuje na: ruchu, uÅ¼yciu skokÃ³w/dash, Å›mierci, odkrywaniu nowych obszarÃ³w.

3. Uczenie siÄ™:
  
  â€¢ Replay buffer (10k doÅ›wiadczeÅ„), losowe prÃ³bkowanie batchy.
  
  â€¢ Obliczanie wartoÅ›ci docelowych Q.
  
  â€¢ Aktualizacja sieci co krok i synchronizacja co 10 epizodÃ³w.

4. Ewolucja agenta:

  â€¢ Z biegiem czasu: mniej losowych akcji, lepsze rozpoznawanie wzorcÃ³w.

  â€¢ Od chaotycznego skakania do strategii z dash i precyzyjnym ruchem.

5. Testowanie:

â€¢ Po 500 epizodach treningu agent testowany jest w 10 rundach z minimalnÄ… eksploracjÄ… (Îµ = 0.01).
